{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium beautifulsoup4\n",
    "# !pip install pandas numpy matplotlib\n",
    "url = \"https://www.magicbricks.com/property-for-sale/residential-real-estate?bedroom=&proptype=Multistorey-Apartment,Builder-Floor-Apartment,Penthouse,Studio-Apartment&cityName=Pune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scroll_and_wait(driver, timeout=10):\n",
    "    try:\n",
    "        # Scroll down to the bottom of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait for the document to be in 'complete' state\n",
    "        WebDriverWait(driver, timeout).until(EC.presence_of_element_located((By.XPATH, '//body[not(@style=\"cursor: wait;\")]/@data-pageloaded]')))\n",
    "    except Exception as e:\n",
    "        print(\"Scrolling and waiting failed: {}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_bhk(description,title):\n",
    "    # Regular expression to find Bhk information\n",
    "    bhk_pattern = re.compile(r'(\\d+)\\s*BHK', re.IGNORECASE)\n",
    "    # Searching for Bhk information in the description\n",
    "    match_dec = bhk_pattern.search(description)\n",
    "    # Searching for Bhk information in the title\n",
    "    match_tlt = bhk_pattern.search(title) \n",
    "\n",
    "\n",
    "    if match_dec:\n",
    "        return int(match_dec.group(1))\n",
    "    elif match_tlt:\n",
    "        return int(match_tlt.group(1))\n",
    "    else:          \n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_values_from_html(property_div):\n",
    "    super_area = None\n",
    "    floor = None\n",
    "    total_floors = None\n",
    "    bathrooms = None\n",
    "\n",
    "    floor_data = None\n",
    "    try:\n",
    "        summary_list_items = property_div.find('div', class_='mb-srp__card__summary__list').find_all('div', class_='mb-srp__card__summary__list--item')\n",
    "\n",
    "        for item in summary_list_items:\n",
    "            label = item.find('div', class_='mb-srp__card__summary--label')\n",
    "            value = item.find('div', class_='mb-srp__card__summary--value')\n",
    "\n",
    "            if label and value:\n",
    "                label_text = label.text.strip().lower()\n",
    "                value_text = value.text.strip().lower().replace(',', '')\n",
    "\n",
    "                if 'super area' in label_text  or \"super_area\" in label_text or \"superarea\" in label_text:\n",
    "                    super_area = value_text.split('')\n",
    "                if 'floor' in label_text or 'floors' in label_text or 'flooring' in label_text:\n",
    "                    floor_data = value_text\n",
    "                    # floor = floor_data[0].strip()\n",
    "                    # total_floors = int(floor_data[1].strip())\n",
    "                if 'bathroom' in label_text:\n",
    "                    bathrooms = int(value_text) if value_text.isdigit() else None\n",
    "    except Exception as e:\n",
    "        print(\"Error in extract_values_from_html function:\", e)\n",
    "\n",
    "    # return super_area, floor, total_floors, bathrooms\n",
    "    return super_area, floor_data, 0, bathrooms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data to write!\n",
      "------------Data written successfully!------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def save_to_csv(data=[], filename='output.csv'):\n",
    "    try:\n",
    "        with open(filename, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Check if the file is empty, if so, write the header\n",
    "            if file.tell() == 0:\n",
    "                header = ['Property_Title', 'Price', 'Rate', 'Bhk', 'Super_area' , 'Floor' , 'Total_floor' ]\n",
    "                writer.writerow(header)\n",
    "                data=[\"null\"]*len(header)\n",
    "                writer.writerow(data)\n",
    "                \n",
    "            if data:\n",
    "                writer.writerow(data)\n",
    "            else:\n",
    "                print(\"No data to write!\")\n",
    "                pass\n",
    "        print(f\"Data written successfully!\".center(50, '-') + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to CSV: {e}\")\n",
    "\n",
    "save_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(property_divs):\n",
    "    try:\n",
    "        c = 1\n",
    "        for property_div in property_divs:\n",
    "            try:  # extracting required data from each div class \"property_div\"\n",
    "                print(f\"{c}/{len(property_divs)}\")\n",
    "                property_title = property_div.find('h2', class_='mb-srp__card--title').text.strip()\n",
    "                property_price = property_div.find('div', class_='mb-srp__card__price--amount').text.strip()\n",
    "                property_price=property_price.replace(\"₹\",\"Rs \")\n",
    "                property_rate_elem = property_div.find('div', class_='mb-srp__card__price--size')\n",
    "                property_rate = property_rate_elem.text.strip().split(' ')[0] if property_rate_elem else 'N/A'\n",
    "                property_rate=property_rate.replace(\"₹\",\"Rs \")\n",
    "                property_description = property_div.find('p', class_='two-line-truncated').text.strip()\n",
    "                property_bhk = extract_bhk(property_description,property_title)\n",
    "                super_area, floor, total_floors, bathrooms = extract_values_from_html(property_div)\n",
    "\n",
    "                print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "                print(\"Property Title:\", property_title)\n",
    "                print(\"Price: {0}\".format(property_price).strip().center(50, '-'))\n",
    "                print(\"BHK: {0}\".format(property_bhk).strip().center(50, '-'))\n",
    "                print(\"Rate: {0}\".format(property_rate).strip().center(50, '-'))\n",
    "                print(\"Super Area: {0} sqft\".format(super_area).strip().center(50, '-'))\n",
    "                print(\"Floor: {0}\".format(floor).strip().center(50, '-'))\n",
    "                print(\"Total Floors: {0}\".format(total_floors).strip().center(50, '-'))\n",
    "                print(\"Bathrooms: {0}\".format(bathrooms or \"No data\").strip().center(50, '-'))\n",
    "                print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "                save_to_csv([property_title, property_price, property_rate, property_bhk, super_area, floor, total_floors])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "                print(\"Extraction failed \".center(50, '-'))\n",
    "                print(e, \"\\n\")\n",
    "                print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "            finally:\n",
    "                c += 1\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        print(\"Caused by :: {e}\".format(e=e).strip().center(50, '-'))\n",
    "        pass\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# ... (other functions and imports)\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # Wait for the initial content to load\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'mb-srp__list')))\n",
    "\n",
    "    while True:\n",
    "        # Scroll and wait for new content\n",
    "        scroll_and_wait(driver)\n",
    "\n",
    "        # Get the updated page source\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Extract property divs\n",
    "        property_divs = soup.find_all('div', class_='mb-srp__list')\n",
    "\n",
    "        # Perform extraction\n",
    "        extraction(property_divs)\n",
    "        \n",
    "        print(len(property_divs))\n",
    "\n",
    "        # Check for an exit condition (customize this based on your requirements)\n",
    "        if len(property_divs) >= 2500:\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Make a linear regression model, random forest, decision tree model of the data extracted to estimate Property value. input variables (x variable): Project, specification(Bhk), Floor, area output (y variable): Property value Note the properties extracted must be unique (Duplicates must be removed in final CSV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load data from CSV file\n",
    "filename = './output.csv'  # Replace with your actual file name\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Preprocess data\n",
    "X = df[['bhk', 'total_floors', 'carpet area', 'super area']]\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "linear_metrics = {'Mean Squared Error': mean_squared_error(y_test, y_pred_linear),\n",
    "                  'R-squared': r2_score(y_test, y_pred_linear)}\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_metrics = {'Mean Squared Error': mean_squared_error(y_test, y_pred_rf),\n",
    "               'R-squared': r2_score(y_test, y_pred_rf)}\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "dt_metrics = {'Mean Squared Error': mean_squared_error(y_test, y_pred_dt),\n",
    "               'R-squared': r2_score(y_test, y_pred_dt)}\n",
    "\n",
    "# Gradient Boosting model\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "gb_metrics = {'Mean Squared Error': mean_squared_error(y_test, y_pred_gb),\n",
    "               'R-squared': r2_score(y_test, y_pred_gb)}\n",
    "\n",
    "# Display metrics\n",
    "print(\"Linear Regression Metrics:\")\n",
    "print(linear_metrics)\n",
    "\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(rf_metrics)\n",
    "\n",
    "print(\"\\nDecision Tree Metrics:\")\n",
    "print(dt_metrics)\n",
    "\n",
    "print(\"\\nGradient Boosting Metrics:\")\n",
    "print(gb_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
